{
 "cells": [
  {
   "cell_type": "raw",
   "id": "62789e86-4d70-41b2-8153-f84ff3b10e98",
   "metadata": {},
   "source": [
    "Objective:  \n",
    "\n",
    "To clean and preprocess raw text data, preparing it for further analysis or input into machine \n",
    "learning models. Students will use Python libraries such as NLTK, re, and Pandas to complete \n",
    "this task."
   ]
  },
  {
   "cell_type": "raw",
   "id": "206cdd33-6093-4095-b124-3afe37a2d436",
   "metadata": {},
   "source": [
    "Step 1 â€” Import libraries & download NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab13936a-3b59-4cea-970b-3671ea2a0370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\vedha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas numpy nltk scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import os\n",
    "\n",
    "# Download once (fixed list)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')                       # ðŸ‘ˆ important\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng') # ðŸ‘ˆ important fix\n",
    "\n",
    "print(\"âœ… Libraries ready\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4169772e-5fd2-448e-828f-1a17075a1cf2",
   "metadata": {},
   "source": [
    "Step 2 â€” Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eafc843f-4d9a-48b2-ad77-c8cf554d3828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully\n",
      "Columns: ['Review_ID', 'Review_Text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"The product is GREAT! Loved it, but itÂ’s a bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Worst product ever!! WouldnÂ’t recommend to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Satisfactory quality, works as expected, no m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Amazing product, I would buy it again and aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"The delivery was slow, but the product is good.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID                                        Review_Text\n",
       "0          1  \"The product is GREAT! Loved it, but itÂ’s a bi...\n",
       "1          2  \"Worst product ever!! WouldnÂ’t recommend to an...\n",
       "2          3  \"Satisfactory quality, works as expected, no m...\n",
       "3          4  \"Amazing product, I would buy it again and aga...\n",
       "4          5  \"The delivery was slow, but the product is good.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your dataset path\n",
    "csv_path = r\"C:\\Users\\vedha\\OneDrive\\Desktop\\Assignment - 5.1\\product_reviews.csv\"\n",
    "\n",
    "# Use latin1 to avoid UnicodeDecodeError\n",
    "df = pd.read_csv(csv_path, encoding=\"latin1\", on_bad_lines=\"skip\")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08e07469-534a-4287-9b18-7063be03b04c",
   "metadata": {},
   "source": [
    "Step 3 â€” Manually select the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e147d2c-6592-4bec-b084-fe9be36348e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"The product is GREAT! Loved it, but itÂ’s a bi...\n",
       "1    \"Worst product ever!! WouldnÂ’t recommend to an...\n",
       "2    \"Satisfactory quality, works as expected, no m...\n",
       "3    \"Amazing product, I would buy it again and aga...\n",
       "4    \"The delivery was slow, but the product is good.\"\n",
       "5    \"Horrible experience, the product broke after ...\n",
       "6    \"Great value for the price! Definitely worth b...\n",
       "7    \"The product didnÂ’t meet my expectations, retu...\n",
       "8    \"IÂ’m satisfied with the purchase, but there ar...\n",
       "9    \"Superb product! Excellent build quality and g...\n",
       "Name: Review_Text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually set the column containing reviews\n",
    "text_col = \"Review_Text\"   # ðŸ‘ˆ change if needed (e.g. \"Review\", \"Text\")\n",
    "\n",
    "# Show first 10 reviews\n",
    "df[text_col].head(10)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a021199-3b74-4737-bbc8-013ac850298a",
   "metadata": {},
   "source": [
    "Step 4 â€” Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec2a7bba-4a23-4ad1-81e7-f2911e497086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing functions ready\n",
      "{'cleaned': 'the product is great loved it but it s a bit pricey', 'tokens': ['the', 'product', 'is', 'great', 'loved', 'it', 'but', 'it', 's', 'a', 'bit', 'pricey'], 'tokens_nostop': ['product', 'great', 'loved', 'bit', 'pricey'], 'stems': ['product', 'great', 'love', 'bit', 'pricey'], 'lemmas': ['product', 'great', 'loved', 'bit', 'pricey'], 'final_text': 'product great loved bit pricey'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text_basic(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def get_wordnet_pos(nltk_pos_tag):\n",
    "    if nltk_pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned = clean_text_basic(text)\n",
    "    tokens = word_tokenize(cleaned)\n",
    "    tokens_nostop = [t for t in tokens if t not in stop_words and len(t) > 1]\n",
    "    stems = [ps.stem(t) for t in tokens_nostop]\n",
    "    pos_tags = pos_tag(tokens_nostop, lang=\"eng\")  # ðŸ‘ˆ ensure correct tagger\n",
    "    lemmas = [lemmatizer.lemmatize(t, get_wordnet_pos(p)) for t, p in pos_tags]\n",
    "    return {\n",
    "        'cleaned': cleaned,\n",
    "        'tokens': tokens,\n",
    "        'tokens_nostop': tokens_nostop,\n",
    "        'stems': stems,\n",
    "        'lemmas': lemmas,\n",
    "        'final_text': \" \".join(lemmas)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Preprocessing functions ready\")\n",
    "\n",
    "# Quick test\n",
    "print(preprocess_text(df[text_col].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df2cf57c-bebf-4219-ab85-d44727328432",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Step 5 â€” Apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bbba3e1-c2e5-45af-98e6-7563591979c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"The product is GREAT! Loved it, but itÂ’s a bi...</td>\n",
       "      <td>the product is great loved it but it s a bit p...</td>\n",
       "      <td>product great loved bit pricey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Worst product ever!! WouldnÂ’t recommend to an...</td>\n",
       "      <td>worst product ever wouldn t recommend to anyone</td>\n",
       "      <td>bad product ever recommend anyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Satisfactory quality, works as expected, no m...</td>\n",
       "      <td>satisfactory quality works as expected no majo...</td>\n",
       "      <td>satisfactory quality work expect major issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Amazing product, I would buy it again and aga...</td>\n",
       "      <td>amazing product i would buy it again and again</td>\n",
       "      <td>amazing product would buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The delivery was slow, but the product is good.\"</td>\n",
       "      <td>the delivery was slow but the product is good</td>\n",
       "      <td>delivery slow product good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Horrible experience, the product broke after ...</td>\n",
       "      <td>horrible experience the product broke after ju...</td>\n",
       "      <td>horrible experience product break one use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Great value for the price! Definitely worth b...</td>\n",
       "      <td>great value for the price definitely worth buying</td>\n",
       "      <td>great value price definitely worth buying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"The product didnÂ’t meet my expectations, retu...</td>\n",
       "      <td>the product didn t meet my expectations return...</td>\n",
       "      <td>product meet expectation return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"IÂ’m satisfied with the purchase, but there ar...</td>\n",
       "      <td>i m satisfied with the purchase but there are ...</td>\n",
       "      <td>satisfied purchase well option available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Superb product! Excellent build quality and g...</td>\n",
       "      <td>superb product excellent build quality and gre...</td>\n",
       "      <td>superb product excellent build quality great c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  \\\n",
       "0  \"The product is GREAT! Loved it, but itÂ’s a bi...   \n",
       "1  \"Worst product ever!! WouldnÂ’t recommend to an...   \n",
       "2  \"Satisfactory quality, works as expected, no m...   \n",
       "3  \"Amazing product, I would buy it again and aga...   \n",
       "4  \"The delivery was slow, but the product is good.\"   \n",
       "5  \"Horrible experience, the product broke after ...   \n",
       "6  \"Great value for the price! Definitely worth b...   \n",
       "7  \"The product didnÂ’t meet my expectations, retu...   \n",
       "8  \"IÂ’m satisfied with the purchase, but there ar...   \n",
       "9  \"Superb product! Excellent build quality and g...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  the product is great loved it but it s a bit p...   \n",
       "1    worst product ever wouldn t recommend to anyone   \n",
       "2  satisfactory quality works as expected no majo...   \n",
       "3     amazing product i would buy it again and again   \n",
       "4      the delivery was slow but the product is good   \n",
       "5  horrible experience the product broke after ju...   \n",
       "6  great value for the price definitely worth buying   \n",
       "7  the product didn t meet my expectations return...   \n",
       "8  i m satisfied with the purchase but there are ...   \n",
       "9  superb product excellent build quality and gre...   \n",
       "\n",
       "                                          final_text  \n",
       "0                     product great loved bit pricey  \n",
       "1                  bad product ever recommend anyone  \n",
       "2       satisfactory quality work expect major issue  \n",
       "3                          amazing product would buy  \n",
       "4                         delivery slow product good  \n",
       "5          horrible experience product break one use  \n",
       "6          great value price definitely worth buying  \n",
       "7                    product meet expectation return  \n",
       "8           satisfied purchase well option available  \n",
       "9  superb product excellent build quality great c...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc = df[text_col].fillna(\"\").astype(str).apply(preprocess_text)\n",
    "\n",
    "df['cleaned'] = proc.apply(lambda x: x['cleaned'])\n",
    "df['tokens'] = proc.apply(lambda x: x['tokens'])\n",
    "df['tokens_nostop'] = proc.apply(lambda x: x['tokens_nostop'])\n",
    "df['stems'] = proc.apply(lambda x: x['stems'])\n",
    "df['lemmas'] = proc.apply(lambda x: x['lemmas'])\n",
    "df['final_text'] = proc.apply(lambda x: x['final_text'])\n",
    "\n",
    "df[[text_col, 'cleaned', 'final_text']].head(10)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7146bc4-6a90-47f2-8ca3-3559ea8b32a7",
   "metadata": {},
   "source": [
    "Step 6 â€” Vocabulary & Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35096d1f-c049-4034-814c-dee16650a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vocabulary size: 74\n",
      "Sample vocab terms: ['advertise', 'amazing', 'anyone', 'available', 'bad', 'bit', 'break', 'build', 'buy', 'buying', 'cheap', 'customer', 'decent', 'defective', 'definitely']\n"
     ]
    }
   ],
   "source": [
    "all_lemmas = df['lemmas'].explode().dropna()\n",
    "vocab = sorted(all_lemmas.unique())\n",
    "print(\"âœ… Vocabulary size:\", len(vocab))\n",
    "\n",
    "term_to_idx = {term: idx for idx, term in enumerate(vocab)}\n",
    "N = len(df)\n",
    "\n",
    "df_counts = np.zeros(len(vocab), dtype=int)\n",
    "for lem_list in df['lemmas']:\n",
    "    if not lem_list:\n",
    "        continue\n",
    "    for t in set(lem_list):\n",
    "        df_counts[term_to_idx[t]] += 1\n",
    "\n",
    "print(\"Sample vocab terms:\", vocab[:15])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f5c5569-7a04-4c85-bba1-d20f66f3ee57",
   "metadata": {},
   "source": [
    "Step 7 â€” TF, IDF, TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e04aa548-48bc-4f53-9db1-90d6336209b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TF-IDF matrix ready: (20, 74)\n"
     ]
    }
   ],
   "source": [
    "V = len(vocab)\n",
    "TF = np.zeros((N, V))\n",
    "\n",
    "# Term Frequency\n",
    "for i, lem_list in enumerate(df['lemmas']):\n",
    "    counts = {}\n",
    "    for t in lem_list:\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    for term, c in counts.items():\n",
    "        idx = term_to_idx[term]\n",
    "        TF[i, idx] = 1.0 + np.log(c + 1.0)\n",
    "\n",
    "# Inverse Document Frequency\n",
    "idf = np.log(N / (1 + df_counts)) + 1.0\n",
    "\n",
    "# TF-IDF\n",
    "TFIDF_raw = TF * idf[np.newaxis, :]\n",
    "\n",
    "# Normalize (L2)\n",
    "from numpy.linalg import norm\n",
    "TFIDF = TFIDF_raw.copy()\n",
    "for i in range(N):\n",
    "    d = norm(TFIDF_raw[i])\n",
    "    if d > 0:\n",
    "        TFIDF[i] = TFIDF_raw[i] / d\n",
    "\n",
    "print(\"âœ… TF-IDF matrix ready:\", TFIDF.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6b9d78f-19c9-4d61-9349-1f67c1270166",
   "metadata": {},
   "source": [
    "Step 8 â€” Show top terms per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3f0e911-cadd-484e-b224-d4d214d2fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review 0:\n",
      "[('loved', 0.5165220882139961), ('pricey', 0.5165220882139961), ('bit', 0.5165220882139961), ('great', 0.40811433517775597), ('product', 0.18181717901116096)]\n",
      "\n",
      "Review 1:\n",
      "[('bad', 0.5067964293540973), ('anyone', 0.5067964293540973), ('ever', 0.5067964293540973), ('recommend', 0.44457599801599057), ('product', 0.17839372065714162)]\n",
      "\n",
      "Review 2:\n",
      "[('major', 0.43402080023458084), ('satisfactory', 0.43402080023458084), ('issue', 0.43402080023458084), ('quality', 0.3807351813230127), ('work', 0.3807351813230127), ('expect', 0.3807351813230127)]\n",
      "\n",
      "Review 3:\n",
      "[('amazing', 0.6302254388004296), ('buy', 0.5528513762159981), ('would', 0.49795360515460996), ('product', 0.22184106747491508)]\n",
      "\n",
      "Review 4:\n",
      "[('slow', 0.6127980527597108), ('good', 0.5375635859059185), ('delivery', 0.5375635859059185), ('product', 0.2157065802191654)]\n"
     ]
    }
   ],
   "source": [
    "def top_k_terms(tfidf_row, k=10):\n",
    "    idxs = np.argsort(tfidf_row)[::-1][:k]\n",
    "    return [(vocab[i], float(tfidf_row[i])) for i in idxs if tfidf_row[i] > 0]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nReview {i}:\")\n",
    "    print(top_k_terms(TFIDF[i], k=10))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a727dfee-1bf6-493f-ad2c-b48a2c06e6a6",
   "metadata": {},
   "source": [
    "Step 9 â€” Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b2ef83-3e88-430c-a60e-3d4fa6679fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Files saved to: C:\\Users\\vedha\\OneDrive\\Desktop\\Assignment - 5.1\\outputs\n"
     ]
    }
   ],
   "source": [
    "outdir = r\"C:\\Users\\vedha\\OneDrive\\Desktop\\Assignment - 5.1\\outputs\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(outdir, \"product_reviews_preprocessed.csv\"), index=False, encoding=\"utf-8\")\n",
    "\n",
    "pd.DataFrame(TFIDF, columns=vocab).to_csv(\n",
    "    os.path.join(outdir, \"tfidf_matrix.csv\"), index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Files saved to:\", outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25163e-baac-49fe-8f87-520944c06ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
